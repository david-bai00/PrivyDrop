// ğŸš€ æ–°æµç¨‹ - æ¥æ”¶ç«¯ä¸»å¯¼çš„æ–‡ä»¶ä¼ è¾“ï¼š
// 1. æ¥æ”¶æ–‡ä»¶å…ƒæ•°æ® (fileMetadata)
// 2. ç”¨æˆ·ç‚¹å‡»ä¸‹è½½ï¼Œå‘é€æ–‡ä»¶è¯·æ±‚ (fileRequest)
// 3. æ¥æ”¶æ‰€æœ‰æ•°æ®å—ï¼Œè‡ªåŠ¨æ£€æµ‹å®Œæ•´æ€§
// 4. å®ŒæˆStoreåŒæ­¥åï¼Œä¸»åŠ¨å‘é€å®Œæˆç¡®è®¤ (fileReceiveComplete/folderReceiveComplete)
// æ–‡ä»¶å¤¹ä¼ è¾“ï¼šé‡å¤å•æ–‡ä»¶æµç¨‹ï¼Œæœ€åå‘é€æ–‡ä»¶å¤¹å®Œæˆç¡®è®¤
import { SpeedCalculator } from "@/lib/speedCalculator";
import WebRTC_Recipient from "./webrtc_Recipient";
import {
  CustomFile,
  fileMetadata,
  WebRTCMessage,
  FolderProgress,
  CurrentString,
  StringMetadata,
  StringChunk,
  FileHandlers,
  FileMeta,
  FileRequest,
  FileReceiveComplete,
  FolderReceiveComplete,
  EmbeddedChunkMeta,
} from "@/types/webrtc";
import { postLogToBackend } from "@/app/config/api";

/**
 * ğŸš€ ä¸¥æ ¼æŒ‰åºç¼“å†²å†™å…¥ç®¡ç†å™¨ - ä¼˜åŒ–å¤§æ–‡ä»¶ç£ç›˜I/Oæ€§èƒ½
 */
class SequencedDiskWriter {
  private writeQueue = new Map<number, ArrayBuffer>();
  private nextWriteIndex = 0;
  private readonly maxBufferSize = 100; // æœ€å¤šç¼“å†²100ä¸ªchunkï¼ˆçº¦6.4MBï¼‰
  private readonly stream: FileSystemWritableFileStream;
  private totalWritten = 0;

  constructor(stream: FileSystemWritableFileStream, startIndex: number = 0) {
    this.stream = stream;
    this.nextWriteIndex = startIndex;
  }

  /**
   * å†™å…¥ä¸€ä¸ªchunkï¼Œè‡ªåŠ¨ç®¡ç†é¡ºåºå’Œç¼“å†²
   */
  async writeChunk(chunkIndex: number, chunk: ArrayBuffer): Promise<void> {
    // 1. å¦‚æœæ˜¯æœŸå¾…çš„ä¸‹ä¸€ä¸ªchunkï¼Œç«‹å³å†™å…¥
    if (chunkIndex === this.nextWriteIndex) {
      await this.flushSequentialChunks(chunk);
      return;
    }

    // 2. å¦‚æœæ˜¯æœªæ¥çš„chunkï¼Œç¼“å†²èµ·æ¥
    if (chunkIndex > this.nextWriteIndex) {
      if (this.writeQueue.size < this.maxBufferSize) {
        this.writeQueue.set(chunkIndex, chunk);
        postLogToBackend(
          `[DEBUG] ğŸ“¦ BUFFERED chunk #${chunkIndex} (waiting for #${this.nextWriteIndex}), queue: ${this.writeQueue.size}/${this.maxBufferSize}`
        );
      } else {
        // ç¼“å†²åŒºæ»¡ï¼Œå¼ºåˆ¶å¤„ç†æœ€æ—©çš„chunkä»¥é‡Šæ”¾ç©ºé—´
        await this.forceFlushOldest();
        this.writeQueue.set(chunkIndex, chunk);
        postLogToBackend(
          `[DEBUG] âš ï¸ BUFFER_FULL, forced flush and buffered chunk #${chunkIndex}`
        );
      }
      return;
    }

    // 3. å¦‚æœæ˜¯è¿‡æœŸçš„chunkï¼Œè®°å½•è­¦å‘Šä½†å¿½ç•¥ï¼ˆå·²å†™å…¥ï¼‰
    postLogToBackend(
      `[DEBUG] âš ï¸ DUPLICATE chunk #${chunkIndex} ignored (already written #${this.nextWriteIndex})`
    );
  }

  /**
   * å†™å…¥å½“å‰chunkå¹¶å°è¯•è¿ç»­å†™å…¥åç»­çš„chunk
   */
  private async flushSequentialChunks(firstChunk: ArrayBuffer): Promise<void> {
    // å†™å…¥å½“å‰chunk
    await this.stream.write(firstChunk);
    this.totalWritten += firstChunk.byteLength;

    postLogToBackend(
      `[DEBUG] âœ“ DISK_WRITE chunk #${this.nextWriteIndex} - ${firstChunk.byteLength} bytes, total: ${this.totalWritten}`
    );

    this.nextWriteIndex++;

    // å°è¯•è¿ç»­å†™å…¥ç¼“å†²ä¸­çš„chunk
    let flushCount = 0;
    while (this.writeQueue.has(this.nextWriteIndex)) {
      const chunk = this.writeQueue.get(this.nextWriteIndex)!;
      await this.stream.write(chunk);
      this.totalWritten += chunk.byteLength;
      this.writeQueue.delete(this.nextWriteIndex);

      flushCount++;
      this.nextWriteIndex++;
    }

    if (flushCount > 0) {
      postLogToBackend(
        `[DEBUG] ğŸ”¥ SEQUENTIAL_FLUSH ${flushCount} chunks, now at #${this.nextWriteIndex}, queue: ${this.writeQueue.size}`
      );
    }
  }

  /**
   * å¼ºåˆ¶åˆ·æ–°æœ€æ—©çš„chunkä»¥é‡Šæ”¾ç¼“å†²åŒºç©ºé—´
   */
  private async forceFlushOldest(): Promise<void> {
    if (this.writeQueue.size === 0) return;

    const oldestIndex = Math.min(...Array.from(this.writeQueue.keys()));
    const chunk = this.writeQueue.get(oldestIndex)!;

    // è­¦å‘Šï¼šéåºå†™å…¥
    postLogToBackend(
      `[DEBUG] âš ï¸ FORCE_FLUSH out-of-order chunk #${oldestIndex} (expected #${this.nextWriteIndex})`
    );

    // ä½¿ç”¨seekåœ¨æ­£ç¡®ä½ç½®å†™å…¥ï¼ˆé™çº§å¤„ç†ï¼‰
    const fileOffset = oldestIndex * 65536; // å‡è®¾æ¯ä¸ªchunk 64KB
    await this.stream.seek(fileOffset);
    await this.stream.write(chunk);
    this.writeQueue.delete(oldestIndex);

    // æ¢å¤åˆ°å½“å‰ä½ç½®
    const currentOffset = this.nextWriteIndex * 65536;
    await this.stream.seek(currentOffset);
  }

  /**
   * è·å–ç¼“å†²åŒºçŠ¶æ€
   */
  getBufferStatus(): {
    queueSize: number;
    nextIndex: number;
    totalWritten: number;
  } {
    return {
      queueSize: this.writeQueue.size,
      nextIndex: this.nextWriteIndex,
      totalWritten: this.totalWritten,
    };
  }

  /**
   * å…³é—­å¹¶æ¸…ç†èµ„æº
   */
  async close(): Promise<void> {
    // å°è¯•åˆ·æ–°æ‰€æœ‰å‰©ä½™çš„chunk
    const remainingIndexes = Array.from(this.writeQueue.keys()).sort(
      (a, b) => a - b
    );
    for (const chunkIndex of remainingIndexes) {
      const chunk = this.writeQueue.get(chunkIndex)!;
      const fileOffset = chunkIndex * 65536;
      await this.stream.seek(fileOffset);
      await this.stream.write(chunk);
      postLogToBackend(
        `[DEBUG] ğŸ’¾ FINAL_FLUSH chunk #${chunkIndex} at cleanup`
      );
    }

    this.writeQueue.clear();
  }
}

/**
 * ğŸš€ æ–°ç‰ˆæœ¬ï¼šç®¡ç†æŒ‰åºåˆ—åŒ–èåˆæ•°æ®åŒ…çš„æ–‡ä»¶æ¥æ”¶çŠ¶æ€
 */
interface ActiveFileReception {
  meta: fileMetadata; // If meta is present, it means this file is currently being received; null means no file is being received.
  chunks: (ArrayBuffer | null)[]; // æŒ‰åºå·æ’åˆ—çš„æ•°æ®å—æ•°ç»„
  receivedSize: number;
  initialOffset: number; // For resuming downloads
  fileHandle: FileSystemFileHandle | null; // Object related to writing to disk -- current file.
  writeStream: FileSystemWritableFileStream | null; // Object related to writing to disk.
  sequencedWriter: SequencedDiskWriter | null; // ğŸš€ æ–°å¢ï¼šä¸¥æ ¼æŒ‰åºå†™å…¥ç®¡ç†å™¨
  completionNotifier: {
    resolve: () => void;
    reject: (reason?: any) => void;
  };
  // ğŸš€ æ–°ç‰ˆæœ¬ï¼šç®€åŒ–çš„æŒ‰åºæ¥æ”¶ç®¡ç†
  receivedChunksCount: number; // å®é™…æ¥æ”¶åˆ°çš„chunkæ•°é‡
  expectedChunksCount: number; // é¢„æœŸçš„chunkæ•°é‡
  chunkSequenceMap: Map<number, boolean>; // è·Ÿè¸ªå“ªäº›chunkå·²ç»æ¥æ”¶ï¼ˆç”¨äºchunkåºå·ï¼‰
  isFinalized?: boolean; // é˜²æ­¢é‡å¤finalizeçš„æ ‡è®°
}

class FileReceiver {
  // region Private Properties
  private readonly webrtcConnection: WebRTC_Recipient;
  private readonly largeFileThreshold: number = 1 * 1024 * 1024 * 1024; // 1 GB, larger files will prompt the user to select a directory for direct disk saving.
  private readonly speedCalculator: SpeedCalculator;
  private fileHandlers: FileHandlers;

  private peerId: string = "";
  private saveDirectory: FileSystemDirectoryHandle | null = null;

  // State Management
  private pendingFilesMeta = new Map<string, fileMetadata>(); // Stores file metadata, fileId: meta
  private folderProgresses: Record<string, FolderProgress> = {}; // Folder progress information, fileId: {totalSize: 0, receivedSize: 0, fileIds: []};
  public saveType: Record<string, boolean> = {}; // fileId or folderName -> isSavedToDisk

  // Active transfer state
  private activeFileReception: ActiveFileReception | null = null;
  private activeStringReception: CurrentString | null = null;
  private currentFolderName: string | null = null; // The name of the folder currently being received, or null if not receiving a folder.

  // Callbacks
  public onFileMetaReceived: ((meta: fileMetadata) => void) | null = null;
  public onStringReceived: ((str: string) => void) | null = null;
  public onFileReceived: ((file: CustomFile) => Promise<void>) | null = null;
  private progressCallback:
    | ((id: string, progress: number, speed: number) => void)
    | null = null;
  // endregion

  constructor(WebRTC_recipient: WebRTC_Recipient) {
    this.webrtcConnection = WebRTC_recipient;
    this.speedCalculator = new SpeedCalculator();

    this.fileHandlers = {
      string: this.handleReceivedStringChunk.bind(this),
      stringMetadata: this.handleStringMetadata.bind(this),
      fileMeta: this.handleFileMetadata.bind(this),
    };

    this.setupDataHandler();
  }

  // region Logging and Error Handling
  private log(
    level: "log" | "warn" | "error",
    message: string,
    context?: Record<string, any>
  ) {
    const prefix = `[FileReceiver]`;
    console[level](prefix, message, context || "");
  }

  private fireError(message: string, context?: Record<string, any>) {
    if (this.webrtcConnection.fireError) {
      // @ts-ignore
      this.webrtcConnection.fireError(message, {
        ...context,
        component: "FileReceiver",
      });
    } else {
      this.log("error", message, context);
    }

    if (this.activeFileReception) {
      // ğŸš€ åœ¨é”™è¯¯æ—¶ä¹Ÿè¦æ¸…ç†SequencedWriter
      if (this.activeFileReception.sequencedWriter) {
        this.activeFileReception.sequencedWriter.close().catch((err) => {
          this.log(
            "error",
            "Error closing sequenced writer during error cleanup",
            { err }
          );
        });
      }

      this.activeFileReception.completionNotifier.reject(new Error(message));
      this.activeFileReception = null;
    }
  }
  // endregion

  // region Setup and Public API
  private setupDataHandler(): void {
    this.webrtcConnection.onDataReceived = this.handleReceivedData.bind(this);
  }

  public setProgressCallback(
    callback: (fileId: string, progress: number, speed: number) => void
  ): void {
    this.progressCallback = callback;
  }

  public setSaveDirectory(directory: FileSystemDirectoryHandle): Promise<void> {
    this.saveDirectory = directory;
    return Promise.resolve();
  }

  /**
   * Requests a single file from the peer.
   */
  public async requestFile(fileId: string, singleFile = true): Promise<void> {
    if (this.activeFileReception) {
      this.log("warn", "Another file reception is already in progress.");
      return;
    }

    if (singleFile) this.currentFolderName = null;

    const fileInfo = this.pendingFilesMeta.get(fileId);
    if (!fileInfo) {
      this.fireError("File info not found for the requested fileId", {
        fileId,
      });
      return;
    }

    const shouldSaveToDisk =
      !!this.saveDirectory || fileInfo.size >= this.largeFileThreshold;

    // Set saveType at the beginning of the request to prevent race conditions in the UI
    this.saveType[fileInfo.fileId] = shouldSaveToDisk;
    if (this.currentFolderName) {
      this.saveType[this.currentFolderName] = shouldSaveToDisk;
    }

    let offset = 0;
    if (shouldSaveToDisk && this.saveDirectory) {
      try {
        const folderHandle = await this.createFolderStructure(
          fileInfo.fullName
        );
        const fileHandle = await folderHandle.getFileHandle(fileInfo.name, {
          create: false,
        });
        const file = await fileHandle.getFile();
        offset = file.size;

        if (offset === fileInfo.size) {
          this.log("log", "File already fully downloaded.", { fileId });
          // Optionally, trigger a "completed" state in the UI directly
          this.progressCallback?.(fileId, 1, 0);
          return; // Skip the request
        }
        this.log("log", `Resuming file from offset: ${offset}`, { fileId });
      } catch (e) {
        // File does not exist, starting from scratch
        this.log("log", "Partial file not found, starting from scratch.", {
          fileId,
        });
        offset = 0;
      }
    }

    const receptionPromise = new Promise<void>((resolve, reject) => {
      const expectedChunksCount = Math.ceil((fileInfo.size - offset) / 65536); // è®¡ç®—é¢„æœŸchunkæ•°é‡

      this.activeFileReception = {
        meta: fileInfo,
        chunks: new Array(expectedChunksCount).fill(null), // ğŸš€ åˆå§‹åŒ–ä¸ºæŒ‰ç´¢å¼•æ’åˆ—çš„ç©ºæ•°ç»„
        receivedSize: 0,
        initialOffset: offset,
        fileHandle: null,
        writeStream: null,
        sequencedWriter: null, // ğŸš€ æ–°å¢ï¼šä¸¥æ ¼æŒ‰åºå†™å…¥ç®¡ç†å™¨
        completionNotifier: { resolve, reject },
        // ğŸš€ æ–°ç‰ˆæœ¬ï¼šç®€åŒ–çš„æŒ‰åºæ¥æ”¶ç®¡ç†
        receivedChunksCount: 0,
        expectedChunksCount: expectedChunksCount,
        chunkSequenceMap: new Map<number, boolean>(),
      };

      postLogToBackend(
        `[DEBUG] ğŸš€ FILE_INIT - ${fileInfo.name}, size: ${fileInfo.size}, chunks: ${expectedChunksCount}`
      );
    });

    if (shouldSaveToDisk) {
      await this.createDiskWriteStream(fileInfo, offset);
    }

    const request: FileRequest = { type: "fileRequest", fileId, offset };
    if (this.peerId) {
      this.webrtcConnection.sendData(JSON.stringify(request), this.peerId);
      this.log("log", "Sent fileRequest", { request });

      // è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å‘é€å®Œæˆ
      postLogToBackend(`[DEBUG] ğŸ“¤ FILE_REQUEST sent`);
    } else {
      postLogToBackend(
        `[Firefox Debug] ERROR: Cannot send fileRequest - no peerId available!`
      );
    }

    return receptionPromise;
  }

  /**
   * Requests all files belonging to a folder from the peer.
   */
  public async requestFolder(folderName: string): Promise<void> {
    const folderProgress = this.folderProgresses[folderName];
    if (!folderProgress || folderProgress.fileIds.length === 0) {
      this.log("warn", "No files found for the requested folder.", {
        folderName,
      });
      return;
    }

    // Pre-calculate total size of already downloaded parts of the folder
    let initialFolderReceivedSize = 0;
    if (this.saveDirectory) {
      for (const fileId of folderProgress.fileIds) {
        const fileInfo = this.pendingFilesMeta.get(fileId);
        if (fileInfo) {
          try {
            const folderHandle = await this.createFolderStructure(
              fileInfo.fullName
            );
            const fileHandle = await folderHandle.getFileHandle(fileInfo.name, {
              create: false,
            });
            const file = await fileHandle.getFile();
            initialFolderReceivedSize += file.size;
          } catch (e) {
            // File doesn't exist, so its size is 0.
          }
        }
      }
    }
    folderProgress.receivedSize = initialFolderReceivedSize;
    this.log(
      "log",
      `Requesting to receive folder, initial received size: ${initialFolderReceivedSize}`,
      { folderName }
    );

    this.currentFolderName = folderName;
    for (const fileId of folderProgress.fileIds) {
      try {
        await this.requestFile(fileId, false);
      } catch (error) {
        this.fireError(
          `Failed to receive file ${fileId} in folder ${folderName}`,
          { error }
        );
        // Stop receiving other files in the folder on error
        break;
      }
    }
    this.currentFolderName = null;

    // ğŸš€ æ–°æµç¨‹ï¼šå‘é€æ–‡ä»¶å¤¹æ¥æ”¶å®Œæˆç¡®è®¤
    // æ”¶é›†æ‰€æœ‰æˆåŠŸå®Œæˆçš„æ–‡ä»¶ID
    const completedFileIds = folderProgress.fileIds.filter((fileId) => {
      // è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„éªŒè¯é€»è¾‘ï¼Œç°åœ¨ç®€å•å‡è®¾éƒ½æˆåŠŸäº†
      return true;
    });

    postLogToBackend(
      `[Firefox Debug] ğŸ“ All files in folder completed - ${folderName}, files: ${completedFileIds.length}/${folderProgress.fileIds.length}`
    );

    // å‘é€æ–‡ä»¶å¤¹å®Œæˆæ¶ˆæ¯
    this.sendFolderReceiveComplete(folderName, completedFileIds, true);
  }
  // endregion

  // region WebRTC Data Handlers

  /**
   * å°†å„ç§äºŒè¿›åˆ¶æ•°æ®æ ¼å¼è½¬æ¢ä¸ºArrayBuffer
   * æ”¯æŒFirefoxçš„Blobã€Uint8Arrayç­‰æ ¼å¼
   */
  private async convertToArrayBuffer(data: any): Promise<ArrayBuffer | null> {
    const originalType = Object.prototype.toString.call(data);

    if (data instanceof ArrayBuffer) {
      return data;
    } else if (data instanceof Blob) {
      try {
        const arrayBuffer = await data.arrayBuffer();
        if (data.size !== arrayBuffer.byteLength) {
          postLogToBackend(
            `[DEBUG] âš ï¸ Blob size mismatch: ${data.size}â†’${arrayBuffer.byteLength}`
          );
        }
        return arrayBuffer;
      } catch (error) {
        postLogToBackend(`[DEBUG] âŒ Blob conversion failed: ${error}`);
        return null;
      }
    } else if (data instanceof Uint8Array || ArrayBuffer.isView(data)) {
      try {
        const uint8Array =
          data instanceof Uint8Array
            ? data
            : new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
        const newArrayBuffer = new ArrayBuffer(uint8Array.length);
        new Uint8Array(newArrayBuffer).set(uint8Array);
        return newArrayBuffer;
      } catch (error) {
        postLogToBackend(`[DEBUG] âŒ TypedArray conversion failed: ${error}`);
        return null;
      }
    } else {
      postLogToBackend(
        `[DEBUG] âŒ Unknown data type: ${Object.prototype.toString.call(data)}`
      );
      return null;
    }
  }

  /**
   * ğŸš€ æ–°å¢ï¼šè§£æèåˆæ•°æ®åŒ…
   * æ ¼å¼: [4å­—èŠ‚é•¿åº¦] + [JSONå…ƒæ•°æ®] + [å®é™…chunkæ•°æ®]
   */
  private parseEmbeddedChunkPacket(arrayBuffer: ArrayBuffer): {
    chunkMeta: EmbeddedChunkMeta;
    chunkData: ArrayBuffer;
  } | null {
    try {
      // 1. æ£€æŸ¥æ•°æ®åŒ…æœ€å°é•¿åº¦
      if (arrayBuffer.byteLength < 4) {
        postLogToBackend(
          `[DEBUG] âŒ Invalid embedded packet - too small: ${arrayBuffer.byteLength}`
        );
        return null;
      }

      // 2. è¯»å–å…ƒæ•°æ®é•¿åº¦ï¼ˆ4å­—èŠ‚ï¼‰
      const lengthView = new Uint32Array(arrayBuffer, 0, 1);
      const metaLength = lengthView[0];

      // 3. éªŒè¯æ•°æ®åŒ…çš„å®Œæ•´æ€§
      const expectedTotalLength = 4 + metaLength;
      if (arrayBuffer.byteLength < expectedTotalLength) {
        postLogToBackend(
          `[DEBUG] âŒ Incomplete embedded packet - expected: ${expectedTotalLength}, got: ${arrayBuffer.byteLength}`
        );
        return null;
      }

      // 4. æå–å…ƒæ•°æ®éƒ¨åˆ†
      const metaBytes = new Uint8Array(arrayBuffer, 4, metaLength);
      const metaJson = new TextDecoder().decode(metaBytes);
      const chunkMeta: EmbeddedChunkMeta = JSON.parse(metaJson);

      // 5. æå–å®é™…chunkæ•°æ®éƒ¨åˆ†
      const chunkDataStart = 4 + metaLength;
      const chunkData = arrayBuffer.slice(chunkDataStart);

      // 6. éªŒè¯chunkæ•°æ®å¤§å°
      if (chunkData.byteLength !== chunkMeta.chunkSize) {
        postLogToBackend(
          `[DEBUG] âš ï¸ Chunk size mismatch - meta: ${chunkMeta.chunkSize}, actual: ${chunkData.byteLength}`
        );
      }

      postLogToBackend(
        `[DEBUG] ğŸ“¦ PARSED embedded packet - chunkIndex: ${chunkMeta.chunkIndex}/${chunkMeta.totalChunks}, chunkSize: ${chunkData.byteLength}, isLast: ${chunkMeta.isLastChunk}`
      );

      return { chunkMeta, chunkData };
    } catch (error) {
      postLogToBackend(`[DEBUG] âŒ Failed to parse embedded packet: ${error}`);
      return null;
    }
  }

  private async handleReceivedData(
    data: string | ArrayBuffer | any,
    peerId: string
  ): Promise<void> {
    this.peerId = peerId;

    if (typeof data === "string") {
      try {
        const parsedData = JSON.parse(data) as WebRTCMessage;

        const handler =
          this.fileHandlers[parsedData.type as keyof FileHandlers];
        if (handler) {
          await handler(parsedData, peerId);
        } else {
          console.warn(
            `[DEBUG] âš ï¸ FileReceiver Handler not found: ${parsedData.type}`
          );
        }
      } catch (error) {
        this.fireError("Error parsing received JSON data", { error });
      }
    } else {
      // ğŸš€ æ–°ç‰ˆæœ¬ï¼šå¤„ç†èåˆæ•°æ®åŒ… - å½»åº•è§£å†³Firefoxä¹±åºé—®é¢˜
      const arrayBuffer = await this.convertToArrayBuffer(data);

      if (arrayBuffer) {
        if (!this.activeFileReception) {
          postLogToBackend(
            `[Firefox Debug] ERROR: Received file chunk but no active file reception!`
          );
          this.fireError(
            "Received a file chunk without an active file reception.",
            { peerId }
          );
          return;
        }

        // ğŸš€ ç»Ÿä¸€å¤„ç†ï¼šæ‰€æœ‰æ•°æ®éƒ½ä½œä¸ºèåˆæ•°æ®åŒ…å¤„ç†
        await this.handleEmbeddedChunkPacket(arrayBuffer);
      } else {
        postLogToBackend(
          `[Firefox Debug] ERROR: Failed to convert binary data to ArrayBuffer`
        );
        this.fireError("Received unsupported binary data format", {
          dataType: Object.prototype.toString.call(data),
          peerId,
        });
      }
    }
  }

  private handleFileMetadata(metadata: fileMetadata): void {
    if (this.pendingFilesMeta.has(metadata.fileId)) {
      return; // Ignore if already received.
    }

    this.pendingFilesMeta.set(metadata.fileId, metadata);

    if (this.onFileMetaReceived) {
      this.onFileMetaReceived(metadata);
    } else {
      console.error(
        `[DEBUG] âŒ FileReceiver onFileMetaReceived callback does not exist!`
      );
    }
    // Record the file size for folder progress calculation.
    if (metadata.folderName) {
      const folderId = metadata.folderName;
      if (!(folderId in this.folderProgresses)) {
        this.folderProgresses[folderId] = {
          totalSize: 0,
          receivedSize: 0,
          fileIds: [],
        };
      }
      const folderProgress = this.folderProgresses[folderId];
      if (!folderProgress.fileIds.includes(metadata.fileId)) {
        // Prevent duplicate calculation
        folderProgress.totalSize += metadata.size;
        folderProgress.fileIds.push(metadata.fileId);
      }
    }
  }

  private handleStringMetadata(metadata: StringMetadata): void {
    this.activeStringReception = {
      length: metadata.length,
      chunks: [],
      receivedChunks: 0,
    };
  }

  private handleReceivedStringChunk(data: StringChunk): void {
    if (!this.activeStringReception) return;

    this.activeStringReception.chunks[data.index] = data.chunk;
    this.activeStringReception.receivedChunks++;

    if (this.activeStringReception.receivedChunks === data.total) {
      const fullString = this.activeStringReception.chunks.join("");
      this.onStringReceived?.(fullString);
      this.activeStringReception = null;
    }
  }

  // endregion

  // region File and Folder Processing

  /**
   * ğŸš€ æ–°ç‰ˆæœ¬ï¼šå¤„ç†èåˆæ•°æ®åŒ…
   */
  private async handleEmbeddedChunkPacket(
    arrayBuffer: ArrayBuffer
  ): Promise<void> {
    const parsed = this.parseEmbeddedChunkPacket(arrayBuffer);
    if (!parsed) {
      this.fireError("Failed to parse embedded chunk packet");
      return;
    }

    const { chunkMeta, chunkData } = parsed;
    const reception = this.activeFileReception!;

    // éªŒè¯fileIdåŒ¹é…
    if (chunkMeta.fileId !== reception.meta.fileId) {
      postLogToBackend(
        `[DEBUG] âš ï¸ FileId mismatch - expected: ${reception.meta.fileId}, got: ${chunkMeta.fileId}`
      );
      return;
    }

    // æ›´æ–°é¢„æœŸ chunks æ•°é‡ï¼ˆå¯èƒ½ä¸åˆå§‹é¢„ä¼°ä¸åŒï¼‰
    if (chunkMeta.totalChunks !== reception.expectedChunksCount) {
      postLogToBackend(
        `[DEBUG] âš ï¸ Chunk count adjustment - expected: ${reception.expectedChunksCount}, actual: ${chunkMeta.totalChunks}`
      );
      reception.expectedChunksCount = chunkMeta.totalChunks;
      // è°ƒæ•´chunksæ•°ç»„å¤§å°
      if (reception.chunks.length < chunkMeta.totalChunks) {
        const newChunks = new Array(chunkMeta.totalChunks).fill(null);
        reception.chunks.forEach((chunk, index) => {
          if (index < newChunks.length) newChunks[index] = chunk;
        });
        reception.chunks = newChunks;
      }
    }

    // æŒ‰åºå·å­˜å‚¨chunk
    const chunkIndex = chunkMeta.chunkIndex;
    if (chunkIndex >= 0 && chunkIndex < reception.chunks.length) {
      reception.chunks[chunkIndex] = chunkData;
      reception.chunkSequenceMap.set(chunkIndex, true);
      reception.receivedChunksCount++;

      postLogToBackend(
        `[DEBUG] âœ“ SEQUENCED chunk #${chunkIndex}/${chunkMeta.totalChunks} stored - size: ${chunkData.byteLength}, isLast: ${chunkMeta.isLastChunk}`
      );

      // æ›´æ–°è¿›åº¦
      this.updateProgress(chunkData.byteLength);

      if (reception.sequencedWriter) {
        // ğŸš€ ä½¿ç”¨ä¸¥æ ¼æŒ‰åºå†™å…¥ç®¡ç†å™¨
        await reception.sequencedWriter.writeChunk(chunkIndex, chunkData);
      } else {
        postLogToBackend(`[DEBUG] âŒ Error - no sequencedWriter available`);
      }
    } else {
      postLogToBackend(
        `[DEBUG] âŒ Invalid chunk index - ${chunkIndex}, expected 0-${
          reception.chunks.length - 1
        }`
      );
    }

    await this.checkAndAutoFinalize();
  }

  /**
   * ğŸš€ æ–°ç‰ˆæœ¬ï¼šç»Ÿä¸€çš„è‡ªåŠ¨å®Œæˆæ£€æŸ¥ - æ”¯æŒèåˆæ•°æ®åŒ…å’Œæ—§æ ¼å¼
   */
  private async checkAndAutoFinalize(): Promise<void> {
    if (!this.activeFileReception) return;

    const reception = this.activeFileReception;
    const receivedChunks = reception.receivedChunksCount;
    const expectedChunks = reception.expectedChunksCount;

    // è®¡ç®—å½“å‰å®é™…æ¥æ”¶çš„æ€»å¤§å°
    const currentTotalSize = reception.chunks.reduce((sum, chunk) => {
      return sum + (chunk instanceof ArrayBuffer ? chunk.byteLength : 0);
    }, 0);
    const expectedSize = reception.meta.size;

    // ğŸš€ ç»Ÿä¸€å®Œæ•´æ€§æ£€æŸ¥ï¼šæŒ‰åºæ¥æ”¶æ¨¡å¼
    let sequencedCount = 0;
    for (let i = 0; i < expectedChunks; i++) {
      if (reception.chunks[i] instanceof ArrayBuffer) {
        sequencedCount++;
      }
    }
    const isSequencedComplete = sequencedCount === expectedChunks;

    const sizeComplete = currentTotalSize >= expectedSize;
    const isDataComplete = isSequencedComplete && sizeComplete;

    // æ›´é¢‘ç¹çš„è°ƒè¯•ä¿¡æ¯åªåœ¨æ¥è¿‘å®Œæˆæ—¶æ˜¾ç¤º
    if (
      receivedChunks % 10 === 0 ||
      receivedChunks >= expectedChunks - 5 ||
      isDataComplete
    ) {
      postLogToBackend(
        `[DEBUG] ğŸ”„ SEQUENCED progress - received: ${sequencedCount}/${expectedChunks}, total: ${currentTotalSize}/${expectedSize}, complete: ${isDataComplete}`
      );
    }

    // é˜²æ­¢é‡å¤finalize
    if (reception.isFinalized) {
      return;
    }

    if (isDataComplete) {
      postLogToBackend(
        `[DEBUG] ğŸ¯ TRIGGERING finalize - chunks: ${sequencedCount}/${expectedChunks}, size: ${currentTotalSize}/${expectedSize}`
      );

      reception.isFinalized = true;

      try {
        await this.finalizeFileReceive();

        if (reception.completionNotifier) {
          reception.completionNotifier.resolve();
        }
        this.activeFileReception = null;

        postLogToBackend(`[DEBUG] âœ… Auto-finalize SUCCESS`);
      } catch (error) {
        postLogToBackend(`[DEBUG] âŒ Auto-finalize ERROR: ${error}`);
        if (reception.completionNotifier) {
          reception.completionNotifier.reject(error);
        }
        this.activeFileReception = null;
      }
    }
  }

  private async finalizeFileReceive(): Promise<void> {
    if (!this.activeFileReception) return;

    if (this.activeFileReception.writeStream) {
      await this.finalizeLargeFileReceive();
    } else {
      await this.finalizeMemoryFileReceive();
    }
  }

  private updateProgress(byteLength: number): void {
    if (!this.peerId || !this.activeFileReception) return;

    this.activeFileReception.receivedSize += byteLength;
    const reception = this.activeFileReception;
    const totalReceived = reception.initialOffset + reception.receivedSize;

    if (this.currentFolderName) {
      const folderProgress = this.folderProgresses[this.currentFolderName];
      if (!folderProgress) return;
      // This is tricky: folder progress needs to sum up individual file progresses.
      // For simplicity, we'll estimate based on total received for the active file.
      // A more accurate implementation would track offsets for all files in the folder.
      folderProgress.receivedSize += byteLength; // This is an approximation

      this.speedCalculator.updateSendSpeed(
        this.peerId,
        folderProgress.receivedSize
      );
      const speed = this.speedCalculator.getSendSpeed(this.peerId);
      const progress =
        folderProgress.totalSize > 0
          ? folderProgress.receivedSize / folderProgress.totalSize
          : 0;
      this.progressCallback?.(this.currentFolderName, progress, speed);
    } else {
      this.speedCalculator.updateSendSpeed(this.peerId, totalReceived);
      const speed = this.speedCalculator.getSendSpeed(this.peerId);
      const progress =
        reception.meta.size > 0 ? totalReceived / reception.meta.size : 0;
      this.progressCallback?.(reception.meta.fileId, progress, speed);
    }
  }
  // endregion

  // region Disk Operations
  private async createDiskWriteStream(
    meta: FileMeta,
    offset: number
  ): Promise<void> {
    if (!this.saveDirectory || !this.activeFileReception) {
      this.log("warn", "Save directory not set, falling back to in-memory.");
      return;
    }

    try {
      const folderHandle = await this.createFolderStructure(meta.fullName);
      const fileHandle = await folderHandle.getFileHandle(meta.name, {
        create: true,
      });
      // Use keepExistingData: true to append
      const writeStream = await fileHandle.createWritable({
        keepExistingData: true,
      });
      // Seek to the offset to start writing from there
      await writeStream.seek(offset);

      this.activeFileReception.fileHandle = fileHandle;
      this.activeFileReception.writeStream = writeStream;

      // ğŸš€ åˆ›å»ºä¸¥æ ¼æŒ‰åºå†™å…¥ç®¡ç†å™¨
      const startChunkIndex = Math.floor(offset / 65536); // è®¡ç®—èµ·å§‹å—ç´¢å¼•
      this.activeFileReception.sequencedWriter = new SequencedDiskWriter(
        writeStream,
        startChunkIndex
      );

      postLogToBackend(
        `[DEBUG] ğŸ“¢ SEQUENCED_WRITER created - startIndex: ${startChunkIndex}, offset: ${offset}`
      );
    } catch (err) {
      this.fireError("Failed to create file on disk", {
        err,
        fileName: meta.name,
      });
    }
  }

  private async createFolderStructure(
    fullName: string
  ): Promise<FileSystemDirectoryHandle> {
    if (!this.saveDirectory) {
      throw new Error("Save directory not set");
    }

    const parts = fullName.split("/");
    parts.pop(); // Remove filename

    let currentDir = this.saveDirectory;
    for (const part of parts) {
      if (part) {
        currentDir = await currentDir.getDirectoryHandle(part, {
          create: true,
        });
      }
    }
    return currentDir;
  }

  private async finalizeLargeFileReceive(): Promise<void> {
    const reception = this.activeFileReception;
    if (!reception?.writeStream || !reception.fileHandle) return;

    try {
      // ğŸš€ å…ˆå…³é—­ä¸¥æ ¼æŒ‰åºå†™å…¥ç®¡ç†å™¨ï¼ˆåˆ·æ–°æ‰€æœ‰ç¼“å†²ï¼‰
      if (reception.sequencedWriter) {
        await reception.sequencedWriter.close();
        const status = reception.sequencedWriter.getBufferStatus();
        postLogToBackend(
          `[DEBUG] ğŸ’¾ SEQUENCED_WRITER closed - totalWritten: ${status.totalWritten}, finalQueue: ${status.queueSize}`
        );
        reception.sequencedWriter = null;
      }

      // ç„¶åå…³é—­æ–‡ä»¶æµ
      await reception.writeStream.close();

      postLogToBackend(`[DEBUG] âœ… LARGE_FILE finalized successfully`);
    } catch (error) {
      this.fireError("Error finalizing large file", { error });
    }
  }
  // endregion

  // region In-Memory Operations
  private async finalizeMemoryFileReceive(): Promise<void> {
    const reception = this.activeFileReception;
    if (!reception) return;

    postLogToBackend(
      `[DEBUG] ğŸ” FINALIZE START - fileName: ${reception.meta.name}, expectedSize: ${reception.meta.size}, chunksArray: ${reception.chunks.length}`
    );

    // ğŸš€ ç®€åŒ–ç‰ˆï¼šéªŒè¯æŒ‰åºæ¥æ”¶çš„æ•°æ®
    let totalChunkSize = 0;
    let validChunks = 0;

    reception.chunks.forEach((chunk, index) => {
      if (chunk instanceof ArrayBuffer) {
        validChunks++;
        totalChunkSize += chunk.byteLength;
      }
    });

    postLogToBackend(
      `[DEBUG] ğŸ“Š SEQUENCED_SUMMARY - valid: ${validChunks}/${reception.chunks.length}, totalSize: ${totalChunkSize}, expected: ${reception.meta.size}`
    );

    // æœ€ç»ˆéªŒè¯
    const sizeDifference = reception.meta.size - totalChunkSize;
    if (sizeDifference !== 0) {
      postLogToBackend(
        `[DEBUG] âŒ SIZE_MISMATCH - missing: ${sizeDifference} bytes`
      );
    } else {
      postLogToBackend(`[DEBUG] âœ… SIZE_VERIFIED - ${totalChunkSize} bytes`);
    }

    // åˆ›å»ºæ–‡ä»¶
    const fileBlob = new Blob(
      reception.chunks.filter(
        (chunk) => chunk instanceof ArrayBuffer
      ) as ArrayBuffer[],
      {
        type: reception.meta.fileType,
      }
    );

    const file = new File([fileBlob], reception.meta.name, {
      type: reception.meta.fileType,
    });

    postLogToBackend(
      `[DEBUG] ğŸ“„ FILE_CREATED - size: ${file.size}, expected: ${
        reception.meta.size
      }, match: ${file.size === reception.meta.size}`
    );

    const customFile = Object.assign(file, {
      fullName: reception.meta.fullName,
      folderName: this.currentFolderName,
    }) as CustomFile;

    let storeUpdated = false;
    if (this.onFileReceived) {
      await this.onFileReceived(customFile);
      await Promise.resolve();
      await new Promise<void>((resolve) => setTimeout(() => resolve(), 0));
      storeUpdated = true;

      postLogToBackend(`[DEBUG] âœ… STORE_UPDATED - ${reception.meta.name}`);
    }

    // å‘é€å®Œæˆç¡®è®¤
    this.sendFileReceiveComplete(
      reception.meta.fileId,
      totalChunkSize,
      validChunks,
      storeUpdated
    );
  }
  // endregion

  // region Communication

  /**
   * å‘é€æ–‡ä»¶æ¥æ”¶å®Œæˆç¡®è®¤ - æ–°çš„æ¥æ”¶ç«¯ä¸»å¯¼æµç¨‹
   */
  private sendFileReceiveComplete(
    fileId: string,
    receivedSize: number,
    receivedChunks: number,
    storeUpdated: boolean
  ): void {
    if (!this.peerId) return;

    const completeMessage: FileReceiveComplete = {
      type: "fileReceiveComplete",
      fileId,
      receivedSize,
      receivedChunks,
      storeUpdated,
    };

    const success = this.webrtcConnection.sendData(
      JSON.stringify(completeMessage),
      this.peerId
    );

    postLogToBackend(
      `[DEBUG] ğŸ“¤ SENT fileReceiveComplete - size: ${receivedSize}, chunks: ${receivedChunks}, success: ${success}`
    );
  }

  /**
   * å‘é€æ–‡ä»¶å¤¹æ¥æ”¶å®Œæˆç¡®è®¤
   */
  private sendFolderReceiveComplete(
    folderName: string,
    completedFileIds: string[],
    allStoreUpdated: boolean
  ): void {
    if (!this.peerId) return;

    const completeMessage: FolderReceiveComplete = {
      type: "folderReceiveComplete",
      folderName,
      completedFileIds,
      allStoreUpdated,
    };

    const success = this.webrtcConnection.sendData(
      JSON.stringify(completeMessage),
      this.peerId
    );

    postLogToBackend(
      `[Firefox Debug] ğŸ“¤ Sent folderReceiveComplete - folderName: ${folderName}, completedFiles: ${completedFileIds.length}, allStoreUpdated: ${allStoreUpdated}, success: ${success}`
    );
  }
  // endregion

  public gracefulShutdown(): void {
    if (this.activeFileReception?.sequencedWriter) {
      this.log(
        "log",
        "Attempting to gracefully close sequenced writer on page unload."
      );
      // ğŸš€ å…ˆå…³é—­ä¸¥æ ¼æŒ‰åºå†™å…¥ç®¡ç†å™¨
      this.activeFileReception.sequencedWriter.close().catch((err) => {
        this.log(
          "error",
          "Error closing sequenced writer during graceful shutdown",
          {
            err,
          }
        );
      });
    }

    if (this.activeFileReception?.writeStream) {
      this.log(
        "log",
        "Attempting to gracefully close write stream on page unload."
      );
      // We don't await this, as beforeunload does not wait for promises.
      // This is a "best effort" attempt to flush the buffer to disk.
      this.activeFileReception.writeStream.close().catch((err) => {
        this.log("error", "Error closing stream during graceful shutdown", {
          err,
        });
      });
    }

    // ğŸ”§ Clean up all internal states to ensure correct file metadata reception upon reconnection
    this.pendingFilesMeta.clear();
    this.folderProgresses = {};
    this.saveType = {};
    this.activeFileReception = null;
    this.activeStringReception = null;
    this.currentFolderName = null;
  }
}

export default FileReceiver;
